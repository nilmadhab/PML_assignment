testA <- data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
testA <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(model, testA)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
str(segmentationOriginal)
# 1. Subset the data to a training set and testing set
# based on the Case variable in the data set.
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
# 2. Set the seed to 125 and fit a CART model with the rpart method
# using all predictor variables and default caret settings.
set.seed(125)
model <- train(Class ~ ., method = "rpart", select = -c(Case), data = train)
set.seed(125)
model <- train(Class ~ ., method = "rpart", data = train)
testA <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(model, testA)
library(pgmm)
install.packages(pgmm)
install.packages("~/Desktop/pgmm_1.0.tar.gz", repos = NULL, type = "source")
library(pgmm)
data(olive)
olive = olive[,-1]
str(olive)
summary(olive)
model <- train(factor(Area) ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
model <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
?train
str(SAheart)
model4 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
meethod = "glm", family = "binomial")
model4 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = SAheart, meethod = "glm", family = "binomial")
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
str(model4)
missClass(model4$predicted, model4$y)
str(model4)
missClass(model4$y, model4$predicted)
model4$predicted
missClass(model4$y, predict(model4)
)
table(model4$y, predict(model4))
table(SAheart$chd, predict(model4))
missClass(SAheart$chd, predict(model4))
model4 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, meethod = "glm", family = "binomial")
missClass(trainSA$chd, predict(model4))
missClass(testSA$chd, predict(model4, newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model5 <- train(y ~ ., data = vowel.train, method = "rf")
?varImp
varImp(model5)
varImp(model5, useModel = rf)
varImp(model5, useModel = "rf")
varImp(model5, value = gcv)
varImp(model5, value = rss)
varImp(model5, value = nsubsets)
# Question 4
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
str(SAheart)
data(SAheart)
set.seed(13234)
str(SAheart)
model4 <- train(factor(chd) ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, meethod = "glm", family = "binomial")
library(caret)
set.seed(13234)
str(SAheart)
model4 <- train(factor(chd) ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, meethod = "glm", family = "binomial")
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
str(model4)
missClass(trainSA$chd, predict(model4))
missClass(factor(trainSA$chd), predict(model4))
?predict
predict(model4)
factor(trainSA$chd)
str(model4)
table(factor(trainSA$chd), predict(model4))
set.seed(13234)
str(SAheart)
model4 <- glm(factor(chd) ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, family = "binomial")
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
str(model4)
missClass(factor(trainSA$chd), predict(model4))
missClass(testSA$chd, predict(model4, newdata = testSA))
# Question 5
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model5 <- train(y ~ ., data = vowel.train, method = "rf")
?varImp
varImp(model5)
str(vowel.train)
str(vowel.test)
varImp(predict(model5, newdata = vowel.test))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
?train
modelrf <- train(y ~ ., data = vowel.train, method = "rf")
modelgbm <- train(y ~ ., data = vowel.train, method = "gbm")
testrf <- predict(modelrf)
testgbm <- predict(modelgbm)
tabel(testrf, vowel.train$y)
table(testrf, vowel.train$y)
testrf <- predict(modelrf, newdata = vowel.test)
testgbm <- predict(modelgbm, newdata = vowel.test)
table(testrf, vowel.train$y)
table(testrf, vowel.test$y)
missClass = function(values,prediction){
sum((prediction  == values) * 1)/length(values)
}
misClass(vowel.test$y, testrf)
missClass(vowel.test$y, testrf)
Accu = function(values,prediction){
sum((prediction  == values) * 1)/length(values)
}
table(testrf, vowel.test$y)
table(testgbm, vowel.test$y)
Accu(vowel.test$y, testrf)
Accu(vowel.test$y, testgbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf <- train(diagnosis ~ ., data = training, method = "rf")
gbm <- train(diagnosis ~ ., data = training, method = "gbm")
lda <- train(diagnosis ~ ., data = training, method = "lda")
rftest <- predict(rf, newdata = testing)
gbmtest <- predict(gbm, newdata = testing)
ldatest <- predict(lda, newdata = testing)
predDF <- data.frame(rftest, gbmtest, ldatest, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., data = predDF, method = "rf")
combPred <- predict(combModFit, predDF)
str(combPred)
Accu(rftest, testing$diagnosis)
Accu(gbmtest, testing$diagnosis)
Accu(ldatest, testing$diagnosis)
Accu(combPred, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso <- train(CompressiveStrength ~ ., data = concrete, method = "lasso")
plot.enet(lasso)
lasso <- train(CompressiveStrength ~ ., data = concrete, method = "lasso")
plot.enet(lasso)
?plot.enet
data(diabetes)
attach(diabetes)
object <- enet(x,y,lambda=1)
par(mfrow=c(2,2))
plot(object)
plot(lasso)
# Question 3
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso <- train(CompressiveStrength ~ ., data = concrete, method = "lasso")
plot.enet(summary(lasso)
)
?plot.enet
?enet
x = concrete[, -c(CompressiveStrength)]
x = concrete[, -c("CompressiveStrength")]
str(concrete)
y = concrete$CompressiveStrength
x = concrete[, -c("CompressiveStrength")]
x = concrete[-c("CompressiveStrength")]
concrete[, 1]
x = concrete[, -c("CompressiveStrength")]
str(concrete)
x = concrete[, -"CompressiveStrength"]
x = concrete[, 1:8]
y = concrete$CompressiveStrength
lasso <- enet(x, y, lambda = 0)
x <- as.matrix(x)
str(x)
lasso <- enet(x, y, lambda = 0)
plot.enet(lasso)
?plot.enet
plot.enet(lasso, use.color = TRUE)
dat = read.csv("/Users/huihuiduan/1_MOOC_of_Coursera_edX_Udacity/47 Practical Machine Learning/gaData.csv")
training = dat[year(dat$date)  2011,]
year(dat$date)
?year
library(date)
install.packages("date")
library(date)
training = dat[year(dat$date)  2011,]
training = dat[year(dat$date) == 2011,]
year(dat$date)
str(dat)
dat
str(dat)
dat$date <- as.Date(dat$date)
str(dat)
training = dat[year(dat$date) == 2011,]
training = dat[as.numeric(format(dat$date, "%Y")) == 2011,]
tstrain = ts(training$visitsTumblr)
str(training)
plot(tstrain)
install.packages("forecast")
library(forecast)
?bats()
m1 <- bats(tstrain)
str(dat)
dat
testing = dat[as.numeric(format(dat$date, "%Y")) == 2012,]
tstest = ts(testing$visitsTumblr)
t1 <- predict(m1, newdata = tstest)
plot(forecast(m1))
plot(forecast(t1))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages("e1071")
install.packages("e1071")
library(e1071)
fit <- svm(x = training[, 1:8], y = training$CompressiveStrength)
str(training)
pred <- predict(fit, newdata = testing)
pred <- predict.svm(fit, newdata = testing)
library(e1071)
fit <- svm(x = training[, 1:8], y = training$CompressiveStrength)
pred <- predict.svm(fit, newdata = testing)
?predict.svm
pred <- predict.svm(fit)
summary(fit)
str(fit)
fit$residuals
sum((fit$residuals)^2)
square(sum((fit$residuals)^2) / length(fit$residuals))
squared(sum((fit$residuals)^2) / length(fit$residuals))
sqrt(sum((fit$residuals)^2) / length(fit$residuals))
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf <- train(diagnosis ~ ., data = training, method = "rf")
gbm <- train(diagnosis ~ ., data = training, method = "gbm")
lda <- train(diagnosis ~ ., data = training, method = "lda")
rftest <- predict(rf, newdata = testing)
gbmtest <- predict(gbm, newdata = testing)
ldatest <- predict(lda, newdata = testing)
warnings()
predDF <- data.frame(rftest, gbmtest, ldatest, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., data = predDF, method = "rf")
combPred <- predict(combModFit, predDF)
str(combPred)
Accu(rftest, testing$diagnosis)
Accu(gbmtest, testing$diagnosis)
Accu(ldatest, testing$diagnosis)
Accu = function(values,prediction){
sum((prediction  == values) * 1)/length(values)
}
Accu(rftest, testing$diagnosis)
Accu(gbmtest, testing$diagnosis)
Accu(ldatest, testing$diagnosis)
Accu(combPred, testing$diagnosis)
dat = read.csv("/Users/huihuiduan/1_MOOC_of_Coursera_edX_Udacity/47 Practical Machine Learning/gaData.csv")
install.packages("date")
library(date)
str(dat)
dat$date <- as.Date(dat$date)
str(dat)
training = dat[as.numeric(format(dat$date, "%Y")) == 2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[as.numeric(format(dat$date, "%Y")) == 2012,]
tstest = ts(testing$visitsTumblr)
library(forecast)
m1 <- bats(tstrain)
t1 <- predict(m1, newdata = tstest)
plot(forecast(t1))
str(t1)
exp(-0.6457)
exp(0.4804)
summary(logistic)
# Create a data frome with two variables: form_design and quote
my_data <- data.frame(form_design = c(rep("Baseline", 595), rep("Variation1", 599),
rep("Variation2", 622), rep("Variation3", 606),
rep("Variation4", 578)),
quote = c(rep(1, 32), rep(0, 595 - 32),
rep(1, 30), rep(0, 599 - 30),
rep(1, 18), rep(0, 622 - 18),
rep(1, 51), rep(0, 606 - 51),
rep(1, 38), rep(0, 578 - 38))
)
# summrize the data
summary(my_data)
with(my_data, table(form_design, quote))
# Change the numerical quote to factor
my_data$quote <- as.factor(my_data$quote)
str(my_data)
plot(quote ~ form_design, data = my_data)
logistic <- glm(quote ~ form_design, data = my_data, family = "binomial")
summary(logistic)
summary(logistic)
summary(logistic)$coef
summary(logistic)$coef[3]
?plot
summary(mtcars)
data(mtcars)
?mtcars
boxplot(mpg ~ am)
data(mtcars)
boxplot(mpg ~ am)
boxplot(mpg ~ am, data = mtcars)
boxplot(mpg ~ am, data = mtcars, xlab = "Transmission (0 = automatic, 1 = manual",
ylab = mpg Miles/(US) gallon, main = "Mile Per Gallon by Automatic and Manual Transmission")
boxplot(mpg ~ am, data = mtcars, xlab = "Transmission (0 = automatic, 1 = manual",
ylab = "mpg Miles/(US) gallon"",
main = "Mile Per Gallon by Automatic and Manual Transmission")
?boxplot
boxplot(mpg ~ am, data = mtcars, xlab = "Transmission (0 = automatic, 1 = manual)",
ylab = "Miles Per gallon"")
boxplot(mpg ~ am, data = mtcars, xlab = "Transmission (0 = automatic, 1 = manual)",
ylab = "Miles Per gallon",
main = "Mile Per Gallon by Automatic and Manual Transmission")
?data
boxplot(mpg ~ am, data = mtcars, xlab = "Transmission (0 = automatic, 1 = manual)",
ylab = "Miles Per gallon",
main = "Mile Per Gallon by Automatic and Manual Transmission")
data(mtcars)
boxplot(mpg ~ am, data = mtcars, xlab = "Transmission (0 = automatic, 1 = manual)",
ylab = "Miles Per gallon",
main = "Figure 1. Mile Per Gallon by Automatic and Manual Transmission")
?data
model <- lm(mpg ~ am, data = mtcars)
fit <- lm(mpg ~ am, data = mtcars)
summary(fit)
?mtcars
fit2 <- lm(mpg ~ am, data = mtcars)
summary(fit2)
coef(fit1)
fit1 <- lm(mpg ~ am, data = mtcars)
summary(fit1)
coef(fit1)
summary(fit1)$coef
summary(fit1)$coef[2, 4]
fit1 <- lm(mpg ~ am, data = mtcars)
summary(fit1)
setwd("~/1_MOOC_of_Coursera_edX_Udacity/47 Practical Machine Learning/Project")
?read.csv
training <- read.csv(file = "pml-training.csv", heaser = TRUE, sep = ",", quote = "")
training <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",", quote = "")
str(training)
summary(training)
training <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",", quote = "", dec = "")
install.packages("varSelRF")
library(varSelRF)
par(mfrow = c(5, 5))
for (i in 1:dim(training)[2]){
boxplot(training[, i] ~ training$X.classe.)
}
dim(training)[2]
for (i in 1:25) {
boxplot(training[, i] ~ training$X.classe.)
}
par(mfrow = c(5, 5))
for (i in 1:25) {
boxplot(training[, i] ~ as.factor(training$X.classe.)
}
?boxplot
boxplot(as.factor(training$X.classe., training[, i])
)
boxplot(as.factor(training$X.classe.), training[, i])
df[,colSums(is.na(df)) != nrow(df)]
traing[,colSums(is.na(training)) != nrow(training)]
training[,colSums(is.na(training)) != nrow(training)]
str(training)
summary(train[, c(6:10, 36:48, 59:67, 83:85, 101, 112:123, 139, 150:159)])
summary(training[, c(6:10, 36:48, 59:67, 83:85, 101, 112:123, 139, 150:159)])
training[,colSums(is.na(training)) > 1]
str(training)
training <- training[,colSums(is.na(training)) > 1]
str(training)
training <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",", quote = "")
training <- training[,colSums(is.na(training)) == 0]
summary(training)
str(training)
par(mfrow = c(5, 5))
for (i in dim(training)[2]) {
boxplot(as.factor(training$X.classe.), training[, i])
}
i
pairs(training)
pairs(training)
pairs(training[, c(1:10, 93)])
pairs(training[, c(1:2, 93)])
pairs(training[, c(3:4, 93)])
pairs(training[, c(5:6, 93)])
training <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",", quote = "")
str(training)
summary(training)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
training <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",", quote = "")
RandomForest = randomForestclasse ~ ., data = training, ntree=200, nodesize=25 )
RandomForest = randomForest(classe ~ ., data = training, ntree=200, nodesize=25 )
PredictForTrain = predict(RandomForest)
table(PredictForTrain, training$classe)
str(training)
87/19622
testing <- read.csv(file = "pml-testing.csv", header = TRUE, sep = ",", quote = "")
str(testing)
testing <- read.csv(file = "pml-testing.csv", header = TRUE, sep = ",", quote = "")
str(testing)
PredictForest = predict(RandomForest, newdata = testing)
testing <- read.csv(file = "pml-testing.csv", header = TRUE, sep = ",", quote = "")
PredictForest = predict(RandomForest, newdata = testing)
str(testing)
str(training)
PredictForest = predict(RandomForest, newdata = testing[, -1])
PredictForest = predict(RandomForest, newdata = testing)
colnames(training)
colnames(testing)
colnames(testing) == colnames(testing)
87/19622
PredictForest = predict(RandomForest, newdata = testing)
str(testing)
testing[, 55] <- null
testing[, 55] <- NA
str(testing)
testing[, 55] <- NULL
str(testing)
PredictForest = predict(RandomForest, newdata = testing)
type(training)
types(training)
type(training[, 1])
?type
typeof(training)
typeof(testing)
data(mtcars)
par(mfrow=c(5,2))
plot(mpg ~ cyl, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Number of Cylinders')
plot(mpg ~ disp, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Displacement')
plot(mpg ~ hp, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Horsepower')
plot(mpg ~ drat, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Rear Axle Ratio')
plot(mpg ~ wt, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Weight')
plot(mpg ~ qsec, data = mtcars, ylab = 'Miles per Gallon', xlab = '1/4 Mile Time')
plot(mpg ~ vs, data = mtcars, ylab = 'Miles per Gallon', xlab = 'V/S')
plot(mpg ~ as.factor(am), data = mtcars, ylab = 'Miles per Gallon', xlab = 'Transmission (0 = auto, 1 = manual)')
plot(mpg ~ gear, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Number of Forward Gears')
plot(mpg ~ carb, data = mtcars, ylab = 'Miles per Gallon', xlab = 'Number of Carburetors')
